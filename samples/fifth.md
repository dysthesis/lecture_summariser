### **1.0 Introduction and Recap**

This lecture delves into the formal definitions and notions of security in cryptography, moving beyond the concept of perfect secrecy to computational security.

#### **1.1. Lecture Recap**

A review of concepts from the previous lecture includes:
*   The **One-Time Pad (OTP)** and its property of **perfect secrecy**.
*   The construction of **stream ciphers** using **Pseudorandom Generators (PRGs)**, where a short seed is expanded into a long keystream.
*   The use of **statistical tests** to verify that a PRG's output is computationally indistinguishable from a truly random stream.
*   **Block ciphers**, including historical (DES) and modern (AES) standards.
*   **Modes of operation** for block ciphers.

#### **1.2. Overview of Security Concepts**

The lecture contrasts different levels and models of security:
*   **Perfect Security:** An information-theoretic notion achieved by the OTP, where the ciphertext reveals absolutely no information about the plaintext. Stream ciphers, however, are not perfectly secure because the key (or seed) is shorter than the message.
*   **Computational Security:** A more practical approach where security holds against adversaries with bounded computational power (e.g., those running in probabilistic polynomial time).
*   **Attack Models:** These define the capabilities of an adversary.
    *   **Ciphertext-Only Attack (COA):** The adversary only has access to ciphertexts.
    *   **Known-Plaintext Attack (KPA):** The adversary has access to a set of plaintext-ciphertext pairs.
    *   **Chosen-Plaintext Attack (CPA):** The adversary can choose plaintexts and receive their corresponding ciphertexts from an encryption oracle.
    *   **Chosen-Ciphertext Attack (CCA):** The adversary can choose ciphertexts and receive their corresponding plaintexts from a decryption oracle.
*   **Adaptive vs. Non-adaptive Attacks:** An adaptive adversary can choose its queries to encryption/decryption oracles based on the results of previous queries. A non-adaptive adversary must decide all its queries in advance.
*   **Indistinguishability:** A core principle in modern cryptography. A scheme is secure if an adversary cannot distinguish between the encryptions of two different messages of their choice, or between a "real" cryptographic object (like a PRG output) and an "ideal" one (a truly random string).

### **2.0 Revisiting Symmetric Key Encryption (SKE)**

A formal definition of a Symmetric Key Encryption (SKE) scheme is foundational to discussing its security.

#### **2.1. Key Concept: Formal Definition of an SKE Scheme**

An SKE scheme `‚Ñ∞` is a tuple of three algorithms `(KeyGen, E, D)` defined over a message space `‚Ñ≥`, a ciphertext space `ùíû`, and a key space `ùí¶`.

1.  **`KeyGen(1^k) ‚Üí k ‚àà ùí¶`**: The key generation algorithm takes a security parameter `k` (sometimes denoted `Œª`) as input and outputs a key `k` from the key space `ùí¶`.
2.  **`E(k, m) ‚Üí c`**: The encryption algorithm takes a key `k ‚àà ùí¶` and a message `m ‚àà ‚Ñ≥` as input and outputs a ciphertext `c ‚àà ùíû`. This can be a probabilistic algorithm.
3.  **`D(k, c) ‚Üí m'`**: The decryption algorithm takes a key `k ‚àà ‚Ñ¶` and a ciphertext `c ‚àà ùíû` as input and outputs a message `m' ‚àà ‚Ñ≥`. This is typically a deterministic algorithm.

#### **2.2. Key Concept: Correctness**

For an SKE scheme to be useful, it must be correct. This means that decrypting a ciphertext must yield the original plaintext.

**Formal Definition:**
An SKE scheme `‚Ñ∞` is correct if for all keys `k ‚àà ùí¶` and all messages `m ‚àà ‚Ñ≥`, the following holds with probability 1:
`D(k, E(k, m)) = m`

This can be expressed as: if `c ‚Üê E(k, m)` and `m' ‚Üê D(k, c)`, then `m = m'`.

### **3.0 Semantic Security**

Semantic security is a formal, game-based definition of security for encryption schemes. It captures the intuition that a ciphertext should reveal no partial information about the underlying plaintext.

#### **3.1. Key Concept: The Semantic Security Game (IND-OT-CPA)**

Semantic security is defined via a game between a **Challenger** and an **Adversary `A`**. This specific game formalises security against a one-time chosen-plaintext attack.

**The Game:**
1.  **Setup:** The Adversary `A` chooses two distinct messages, `m‚ÇÄ` and `m‚ÇÅ`, from the message space `‚Ñ≥`. A critical constraint is that the messages must have the same length: `|m‚ÇÄ| = |m‚ÇÅ|`. The adversary sends these to the Challenger.
2.  **Challenge:** The Challenger secretly and uniformly at random selects a bit `b ‚àà {0, 1}`. It then generates a fresh key `k ‚Üê KeyGen(1^k)` and computes the challenge ciphertext `c ‚Üê E(k, m_b)`. The Challenger sends `c` back to the Adversary.
3.  **Guess:** After receiving `c`, the Adversary `A` must output a guess, `b'`, for the bit `b`.
4.  **Winning:** The Adversary wins the game if its guess is correct, i.e., `b' = b`.

The game can be viewed as two distinct experiments, `EXP(0)` and `EXP(1)`, where in `EXP(b)`, the Challenger encrypts `m_b`. The adversary's goal is to distinguish which experiment was run.

**Diagram of the Game:**
```
      Challenger                           Adversary A
      ----------                           -----------
      b R {0, 1}
      k ‚Üê KeyGen()
                                     m‚ÇÄ, m‚ÇÅ  (where |m‚ÇÄ|=|m‚ÇÅ|)
                                     --------------------------->
      c ‚Üê E(k, m_b)
                                     <---------------------------
                                           c

                                     b' ‚àà {0, 1}
                                     --------------------------->
```

#### **3.2. Key Concept: Adversarial Advantage**

The advantage of an adversary `A` in the semantic security game measures how much better `A` is at guessing the bit `b` than random chance (which would be a probability of 1/2).

Let `W_b` be the event that the adversary outputs `1` when the challenger's bit was `b`.
*   `Pr[W‚ÇÄ]` is the probability that `A` outputs `1` given an encryption of `m‚ÇÄ`.
*   `Pr[W‚ÇÅ]` is the probability that `A` outputs `1` given an encryption of `m‚ÇÅ`.

The **Semantic Security Advantage** of `A` against the scheme `‚Ñ∞` is defined as:
`AdvSS[A, ‚Ñ∞] := | Pr[W‚ÇÄ] - Pr[W‚ÇÅ] |`

Alternatively, this can be expressed as: `Adv[A, ‚Ñ∞] = 2 * | Pr[A wins] - 1/2 |`.

#### **3.3. Key Concept: Definition of Security**

An encryption scheme `‚Ñ∞` is **semantically secure** if for all efficient (Probabilistic Polynomial Time, or PPT) adversaries `A`, the advantage `AdvSS[A, ‚Ñ∞]` is a **negligible function** in the security parameter `k`.

A negligible function `negl(k)` is one that decreases faster than the inverse of any polynomial in `k`. Intuitively, this means the adversary's advantage is effectively zero for any practical security level.

#### **3.4. Example: Breaking Semantic Security with an LSB Oracle**

This example demonstrates that if an adversary can learn even a single bit of information about the plaintext from the ciphertext, the scheme is not semantically secure.

**Scenario:** Suppose we have an efficient adversary `A` that, given a ciphertext `c`, can always correctly deduce the Least Significant Bit (LSB) of the original plaintext. We will use `A` to construct another adversary, `B`, that wins the semantic security game with a non-negligible advantage.

**Adversary `B`'s Strategy:**
`B` plays the semantic security game against a challenger for the scheme `‚Ñ∞`.
1.  **Setup:** `B` chooses two messages, `m‚ÇÄ` and `m‚ÇÅ`, such that `LSB(m‚ÇÄ) = 0` and `LSB(m‚ÇÅ) = 1`. `B` sends these to its challenger.
2.  **Challenge:** The challenger responds with a ciphertext `c = E(k, m_b)` for some secret bit `b`.
3.  **Guess:** `B` feeds the ciphertext `c` to the given adversary `A`. Since `A` can deduce the LSB of the encrypted message, `A` will output `LSB(m_b)`. By our construction, `LSB(m_b) = b`. Therefore, `B` uses `A`'s output as its own guess, `b'`.

**Analysis of `B`'s Advantage:**
*   If the challenger's bit was `b=0`, `A` receives `c = E(k, m‚ÇÄ)` and outputs `LSB(m‚ÇÄ) = 0`. So, `B` guesses `0`.
*   If the challenger's bit was `b=1`, `A` receives `c = E(k, m‚ÇÅ)` and outputs `LSB(m‚ÇÅ) = 1`. So, `B` guesses `1`.

`B` always wins. Let's calculate its advantage formally:
`Pr[B outputs 1 | b=0] = Pr[W‚ÇÄ] = 0`
`Pr[B outputs 1 | b=1] = Pr[W‚ÇÅ] = 1`

`AdvSS[B, ‚Ñ∞] = | Pr[W‚ÇÄ] - Pr[W‚ÇÅ] | = |0 - 1| = 1`

Since the advantage is 1 (which is non-negligible), the encryption scheme `‚Ñ∞` is **not semantically secure**. This method of using a hypothetical adversary for one task to build a winning adversary for another is a standard proof technique called a **security reduction**.

### **4.0 Relationship to Other Security Notions**

#### **4.1. Key Concept: Message Recovery Attacks**

Intuitively, a basic security requirement is that an adversary should not be able to recover the entire plaintext from a ciphertext. We can formalise this and show that semantic security is a stronger guarantee.

**The Message Recovery (MR) Game:**
1.  **Challenge:** The Challenger chooses a message `m` uniformly at random from the message space `‚Ñ≥` (`m R ‚Ñ≥`). It generates a key `k R ùí¶` and computes `c ‚Üê E(k, m)`. The challenger sends `c` to the Adversary `A`.
2.  **Guess:** The Adversary `A` outputs a guess `mÃÇ ‚àà ‚Ñ≥`.
3.  **Winning:** The Adversary wins if `mÃÇ = m`.

The probability of winning by random guessing is `1/|‚Ñ≥|`. The **Message Recovery Advantage** is defined as how much better the adversary does than random guessing:
`AdvMR[A, ‚Ñ∞] = |Pr[A wins] - 1/|‚Ñ≥||`

#### **4.2. Proof Sketch: Semantic Security implies Security against Message Recovery**

We can prove that if a scheme `‚Ñ∞` is semantically secure, then no efficient adversary can succeed in a message recovery attack with non-negligible advantage. The proof is a reduction: we assume an adversary `A` exists that can win the MR game and use it to build an adversary `B` that breaks semantic security.

**Adversary `B`'s Strategy (using MR adversary `A`):**
`B` plays the semantic security game against a challenger.
1.  **Setup:** `B` chooses two messages: `m‚ÇÄ` is a fixed, arbitrary message, and `m‚ÇÅ` is chosen uniformly at random from `‚Ñ≥`. `B` sends `m‚ÇÄ, m‚ÇÅ` to its challenger.
2.  **Challenge:** The challenger returns `c = E(k, m_b)`.
3.  **Guess:** `B` gives `c` to the MR adversary `A`. `A` returns a guess `mÃÇ`. `B` then makes its own guess `b'` as follows:
    *   If `mÃÇ = m‚ÇÅ`, `B` guesses `b' = 1`.
    *   Otherwise, `B` guesses `b' = 0`.

**Analysis of `B`'s Advantage:**
Let `p` be the probability that adversary `A` wins the MR game, i.e., `p = Pr[A(E(k,m))=m]`.
Let `p_b` be the probability that `B` outputs `1` when the challenger's bit is `b`.
`AdvSS[B, ‚Ñ∞] = |p‚ÇÄ - p‚ÇÅ|`

*   **Case b=1:** The challenge is `c = E(k, m‚ÇÅ)`. `A` receives an encryption of the message it is trying to guess. The probability that `A` outputs `m‚ÇÅ` is exactly its success probability, `p`. Since `B` outputs `1` if and only if `A` outputs `m‚ÇÅ`, we have `p‚ÇÅ = p`.
*   **Case b=0:** The challenge is `c = E(k, m‚ÇÄ)`. `A`'s output `mÃÇ` is now independent of `m‚ÇÅ` (since `m‚ÇÅ` was chosen randomly by `B` and never used by the challenger). The probability that `A`'s output happens to equal `m‚ÇÅ` is the same as random guessing, so `p‚ÇÄ = 1/|‚Ñ≥|`.

Putting it together:
`AdvSS[B, ‚Ñ∞] = |p‚ÇÄ - p‚ÇÅ| = |1/|‚Ñ≥| - p| = |p - 1/|‚Ñ≥|| = AdvMR[A, ‚Ñ∞]`

This reduction shows that the advantage of adversary `B` in the semantic security game is equal to the advantage of adversary `A` in the message recovery game. Therefore, if `‚Ñ∞` is semantically secure, `AdvSS[B, ‚Ñ∞]` must be negligible, which implies `AdvMR[A, ‚Ñ∞]` must also be negligible.

### **5.0 Security of Specific Ciphers**

#### **5.1. Proof: One-Time Pad (OTP) is Semantically Secure**

We can formally prove that the OTP meets the definition of semantic security.

**Game Analysis:**
Consider the semantic security game for OTP, where `E(k, m) = k ‚äï m`.
*   In `EXP(0)`, the adversary receives `c‚ÇÄ = k ‚äï m‚ÇÄ`.
*   In `EXP(1)`, the adversary receives `c‚ÇÅ = k ‚äï m‚ÇÅ`.

Since the key `k` is chosen uniformly at random from `{0,1}^n` and is used only once, both `c‚ÇÄ` and `c‚ÇÅ` are uniformly random strings in `{0,1}^n`. The distributions of the ciphertexts in both experiments are identical. An adversary receiving a uniformly random string can gain no information to distinguish whether it came from `m‚ÇÄ` or `m‚ÇÅ`.

**Formal Advantage Calculation:**
For any adversary `A` (even an unbounded one):
`Pr[A outputs 1 | c = k ‚äï m‚ÇÄ] = Pr[A outputs 1 | c = k ‚äï m‚ÇÅ]`
Because the inputs `k ‚äï m‚ÇÄ` and `k ‚äï m‚ÇÅ` follow the same probability distribution (the uniform distribution on n-bit strings).
Therefore, `Pr[W‚ÇÄ] = Pr[W‚ÇÅ]`.

`AdvSS[A, OTP] = | Pr[W‚ÇÄ] - Pr[W‚ÇÅ] | = 0`

Since the advantage is 0 (which is negligible), the OTP is semantically secure.

### **6.0 Indistinguishability and Pseudorandom Generators (PRGs)**

The concept of indistinguishability is central to proving the security of practical ciphers like stream ciphers, which rely on PRGs.

#### **6.1. Key Concept: Indistinguishability**

Indistinguishability is a general principle, often illustrated by the Turing Test (1950), where a human judge tries to distinguish between another human and a machine based on conversation. If the judge cannot tell them apart with significant success, the machine is said to be indistinguishable from a human in that context.

In cryptography, we apply this to computational objects. A **distinguisher** is an efficient (PPT) algorithm that tries to tell two types of objects apart.

#### **6.2. Key Concept: PRG Security via Indistinguishability**

A Pseudorandom Generator `G: ùí¶ ‚Üí {0,1}^n` (where `|s| < n`) expands a short random seed `s ‚àà ùí¶` into a longer pseudorandom string `G(s)`.

**The PRG Indistinguishability Game:**
1.  **Challenge:** A challenger flips a coin.
    *   If heads, it generates a truly random string `r` of length `n` (`r R {0,1}^n`).
    *   If tails, it generates a random seed `s R ùí¶` and computes the pseudorandom string `y = G(s)`.
    The challenger sends the resulting string (`r` or `y`) to a **Distinguisher** `D`.
2.  **Guess:** The distinguisher `D` outputs a bit: `1` if it thinks the string was pseudorandom, `0` if it thinks it was truly random.

**Definition of a Secure PRG:**
A PRG `G` is **secure** if its output is **computationally indistinguishable** from a truly random string. Formally, for any efficient distinguisher `D`, its advantage must be negligible:
`AdvPRG[D, G] := | Pr[D(G(s)) = 1] - Pr[D(r) = 1] | ‚â§ negl(k)`

#### **6.3. Theorem: Secure PRG implies Semantically Secure Stream Cipher**

This is a cornerstone theorem for practical symmetric cryptography.
**Theorem:** If `G` is a secure PRG, then the stream cipher `E` constructed from it, where `E(s, M) = G(s) ‚äï M`, is semantically secure.

**Proof Sketch:**
The proof is a reduction. We show that for any adversary `A` that can break the semantic security of the stream cipher `E`, we can construct a distinguisher `B` that breaks the security of the PRG `G`.
`‚àÄ SS adversary A, ‚àÉ a PRG distinguisher B s.t. AdvSS[A, E] ‚â§ 2 * AdvPRG[B, G]`

**Intuition:**
The semantic security game for the stream cipher involves distinguishing `c‚ÇÄ = G(s) ‚äï m‚ÇÄ` from `c‚ÇÅ = G(s) ‚äï m‚ÇÅ`. The security of the PRG states that `G(s)` is indistinguishable from a truly random string `r`.
This suggests that the stream cipher game `(distinguishing E(s,m‚ÇÄ) from E(s,m‚ÇÅ))` should be as hard as the OTP game `(distinguishing r ‚äï m‚ÇÄ from r ‚äï m‚ÇÅ)`. We know the OTP game is impossible to win. The "gap" in security between the stream cipher and the ideal OTP is entirely dependent on the "gap" in quality between the PRG output `G(s)` and a truly random string `r`.

**The Reduction (Constructing Distinguisher `B` from Adversary `A`):**
1.  Distinguisher `B` is given a challenge string `y` (which is either truly random `r` or pseudorandom `G(s)`) from its PRG challenger. `B` must guess the origin of `y`.
2.  `B` will use the SS adversary `A` to help it guess. `B` simulates the semantic security challenger for `A`.
3.  `B` receives `m‚ÇÄ, m‚ÇÅ` from `A`.
4.  `B` computes a ciphertext `c = y ‚äï m‚ÇÄ` and sends it to `A`.
5.  `A` responds with its guess `b'`. `B` uses this to make its own decision. Let's say `B` outputs `1` if `A` outputs `1`.

**Analysis:**
Let's analyze the probability that `B` outputs 1.
`AdvPRG[B, G] = | Pr[B(r) = 1] - Pr[B(G(s)) = 1] |`
*   `Pr[B(G(s)) = 1]`: Here, `y = G(s)`. `B` gives `c = G(s) ‚äï m‚ÇÄ` to `A`. The probability that `A` outputs `1` is exactly `Pr[W‚ÇÄ]` from the original SS game.
*   `Pr[B(r) = 1]`: Here, `y = r`. `B` gives `c = r ‚äï m‚ÇÄ` to `A`. This is an OTP encryption of `m‚ÇÄ`. Let `Pr[R‚ÇÄ]` be the probability `A` outputs `1` in this OTP scenario.

So, `AdvPRG[B, G] = | Pr[R‚ÇÄ] - Pr[W‚ÇÄ] |`.

Using a proof technique involving a "hybrid argument" or the triangle inequality, we can relate the terms:
`AdvSS[A, E] = |Pr[W‚ÇÄ] - Pr[W‚ÇÅ]| ‚â§ |Pr[W‚ÇÄ] - Pr[R‚ÇÄ]| + |Pr[R‚ÇÄ] - Pr[R‚ÇÅ]| + |Pr[R‚ÇÅ] - Pr[W‚ÇÅ]|`

*   `|Pr[R‚ÇÄ] - Pr[R‚ÇÅ]| = AdvSS[A, OTP] = 0`, as shown before.
*   `|Pr[W‚ÇÄ] - Pr[R‚ÇÄ]| = AdvPRG[B, G]` for the adversary `B` we constructed using `m‚ÇÄ`.
*   `|Pr[W‚ÇÅ] - Pr[R‚ÇÅ]| = AdvPRG[B', G]` for a similar adversary `B'` constructed using `m‚ÇÅ`.

Assuming the best distinguisher can be constructed, this leads to the result: `AdvSS[A, E] ‚â§ 2 * AdvPRG[B, G]`.
Since `G` is a secure PRG, `AdvPRG[B, G]` is negligible. Therefore, `AdvSS[A, E]` must also be negligible, proving that the stream cipher `E` is semantically secure.

### **7.0 Summary and Methodological Takeaways**

The lecture establishes the modern, formal approach to proving cryptographic security. The key methodology for creating a security proof is as follows:

1.  **Define the Attack Model/Game:** Clearly specify the capabilities of the adversary and the rules of interaction with a challenger (e.g., semantic security game, message recovery game).
2.  **Define Adversarial Advantage:** Quantify what it means for an adversary to "win" the game, measuring its success relative to random guessing. A scheme is secure if this advantage is negligible for any efficient adversary.
3.  **Prove Security via Reduction:** To prove a new construction (e.g., a stream cipher) is secure, show that any adversary who breaks the new construction can be used as a subroutine to solve a problem believed to be hard (e.g., distinguishing a PRG's output from random). This demonstrates that the new construction is "at least as hard to break" as the underlying primitive.

